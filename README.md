# ğŸŒ¾ Sistema de RecomendaciÃ³n de Cultivos - Proyecto ML

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto desarrolla un sistema inteligente de Machine Learning para recomendar el cultivo mÃ¡s adecuado basÃ¡ndose en parÃ¡metros agroclimÃ¡ticos y propiedades del suelo. Utiliza la metodologÃ­a **CRISP-DM** (Cross-Industry Standard Process for Data Mining) y estÃ¡ implementado en Python con Jupyter Notebooks.

### ğŸ¯ Objetivo

Predecir el cultivo Ã³ptimo para sembrar considerando:
- Nutrientes del suelo (N, P, K)
- Condiciones climÃ¡ticas (Temperatura, Humedad, PrecipitaciÃ³n)
- Propiedades quÃ­micas (pH)

### ğŸ“Š Dataset

- **Fuente**: [Kaggle - Crop Recommendation Dataset](https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset)
- **TamaÃ±o**: 2,200 muestras
- **CaracterÃ­sticas**: 7 variables numÃ©ricas
- **Clases**: 22 tipos de cultivos

## ğŸ—‚ï¸ Estructura del Proyecto

```
proyecto-recomendacion-cultivos/
â”‚
â”œâ”€â”€ README.md                         # Este archivo
â”œâ”€â”€ requirements.txt                  # Dependencias de Python
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_bu_du_eda.ipynb             # Fase 1 CRISP-DM
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ procesamiento_datos.py        # Utilidades de datos
â”‚   â”œâ”€â”€ ingenieria_features.py        # Feature engineering
â”‚   â”œâ”€â”€ entrenamiento_modelo.py       # Entrenamiento
â”‚   â””â”€â”€ evaluacion.py                 # MÃ©tricas y evaluaciÃ³n
â”‚
â”œâ”€â”€ modelos/                          # Modelos guardados
â”‚   â”œâ”€â”€ label_encoder.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ mejor_modelo.pkl
â”‚
â”œâ”€â”€ reportes/
â”‚   â”œâ”€â”€ figuras/                      # Visualizaciones
â”‚   â”œâ”€â”€ reporte_entrega1.pdf
â”‚   â”œâ”€â”€ reporte_entrega2.pdf
    â””â”€â”€ reporte_final.pdf
```

## ğŸš€ Inicio RÃ¡pido

### 1ï¸âƒ£ Requisitos Previos

- Python 3.12 o superior
- pip (gestor de paquetes de Python)
- Git

### 2ï¸âƒ£ InstalaciÃ³n

```bash
# Clonar el repositorio
git clone <url-del-repositorio>
cd proyecto-recomendacion-cultivos

# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En Linux/Mac:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### 3ï¸âƒ£ Ejecutar los Notebooks

```bash
# Iniciar Jupyter Notebook
jupyter notebook

# O usar Jupyter Lab
jupyter lab
```

Ejecutar los notebooks en orden:
1. `1_bu_du_eda.ipynb`


## ğŸ“… Cronograma de Entregas

### Entrega 1 - 02/10/2025 (5%)
- âœ… Notebook de EDA completo
- âœ… Data Card del dataset
- âœ… Modelo baseline (RegresiÃ³n LogÃ­stica)
- âœ… Reporte PDF breve
- âœ… Repositorio Git

**Contenido**: Notebooks `1_bu_du_eda.ipynb`

### Entrega 2 - 09/10/2025 (10%)
- âœ… ComparaciÃ³n de 2-3 familias de modelos
- âœ… Pipelines de entrenamiento
- âœ… ValidaciÃ³n cruzada
- âœ… AnÃ¡lisis de hiperparÃ¡metros
- âœ… Reporte de resultados

**Contenido**: 

### Entrega 3 - 05/11/2025 (20%)
- âœ… Modelo final optimizado
- âœ… InterpretaciÃ³n del modelo (SHAP)
- âœ… Reporte final completo
- âœ… PÃ³ster del proyecto
- âœ… PresentaciÃ³n

**Contenido**: 

## ğŸ¯ MetodologÃ­a CRISP-DM

### Fase 1: ComprensiÃ³n del Negocio
- DefiniciÃ³n del problema
- Objetivos y criterios de Ã©xito
- AnÃ¡lisis de stakeholders

### Fase 2: ComprensiÃ³n de los Datos
- AnÃ¡lisis Exploratorio de Datos (EDA)
- EstadÃ­sticas descriptivas
- IdentificaciÃ³n de patrones
- Data Card

### Fase 3: PreparaciÃ³n de los Datos
- Limpieza de datos
- Manejo de outliers
- Escalado de caracterÃ­sticas
- DivisiÃ³n train-test

### Fase 4: Modelado
- Modelo baseline (RegresiÃ³n LogÃ­stica)
- Ãrboles de DecisiÃ³n
- Random Forest
- XGBoost / LightGBM
- SVM
- Ajuste de hiperparÃ¡metros

### Fase 5: EvaluaciÃ³n
- MÃ©tricas: Accuracy, Precision, Recall, F1-Score
- Matriz de confusiÃ³n
- ValidaciÃ³n cruzada
- ComparaciÃ³n de modelos
- Interpretabilidad (SHAP)

### Fase 6: Despliegue
- SerializaciÃ³n del modelo
- API de predicciÃ³n (opcional)
- DocumentaciÃ³n
- Recomendaciones

---

## ğŸ”§ Conceptos Clave de Machine Learning

### ğŸ›ï¸ OptimizaciÃ³n de HiperparÃ¡metros

#### Â¿Por quÃ© Optimizar HiperparÃ¡metros?

Los valores por defecto de los algoritmos de ML rara vez son Ã³ptimos para un problema especÃ­fico. La optimizaciÃ³n de hiperparÃ¡metros busca encontrar la mejor configuraciÃ³n del modelo.

```mermaid
graph TD
    A[HiperparÃ¡metros por Defecto] -->|Accuracy: 99.5%| B[Modelo Base]
    C[HiperparÃ¡metros Optimizados] -->|Accuracy: 99.8%+| D[Modelo Mejorado]

    B --> E[Posible Overfitting]
    D --> F[Mejor GeneralizaciÃ³n]

    style A fill:#ffcccc
    style C fill:#ccffcc
    style D fill:#99ff99
```

**Beneficios de la optimizaciÃ³n:**
- âœ… **Mejorar accuracy**: TÃ­picamente +0.5% a +3% de mejora
- âœ… **Reducir overfitting**: Modelos que generalizan mejor
- âœ… **Acelerar entrenamiento**: ConfiguraciÃ³n mÃ¡s eficiente
- âœ… **Aumentar estabilidad**: Predicciones mÃ¡s consistentes

#### TÃ©cnicas de OptimizaciÃ³n

```mermaid
graph TD
    A[Espacio de HiperparÃ¡metros] --> B{Â¿CuÃ¡ntos parÃ¡metros?}
    B -->|Pocos â‰¤4| C[GridSearchCV]
    B -->|Muchos >4| D[RandomizedSearchCV]

    C --> F[BÃºsqueda Exhaustiva]
    D --> G[BÃºsqueda Aleatoria]

    F --> I[Garantiza Ã³ptimo<br/>pero LENTO]
    G --> J[RÃ¡pido<br/>buena exploraciÃ³n]

    style C fill:#ffcccc
    style D fill:#ccffcc
```

| TÃ©cnica | DescripciÃ³n | CuÃ¡ndo Usarla | Ventajas | Desventajas |
|---------|-------------|---------------|----------|-------------|
| **GridSearchCV** | BÃºsqueda exhaustiva en grilla de valores | Pocos hiperparÃ¡metros (â‰¤4) | Encuentra el Ã³ptimo global | Muy lento, crecimiento exponencial |
| **RandomizedSearchCV** | BÃºsqueda aleatoria en distribuciones | Muchos hiperparÃ¡metros (>4) | Mucho mÃ¡s rÃ¡pido, buena exploraciÃ³n | No garantiza el Ã³ptimo global |

#### ValidaciÃ³n con K-Fold Cross-Validation

**Importante**: Los hiperparÃ¡metros se optimizan usando **K-Fold Cross-Validation** sobre el conjunto de entrenamiento. Nunca se debe usar el Test Set para optimizaciÃ³n (causa data leakage).

```mermaid
graph TD
    A[Dataset Completo<br/>2200 muestras] --> B[Split Inicial]
    B --> C[Train: 80%<br/>1760 muestras]
    B --> D[Test: 20%<br/>440 muestras<br/>NUNCA SE TOCA]

    C --> E[5-Fold CV sobre Train]

    E --> F1[Fold 1: 1408 train, 352 val]
    E --> F2[Fold 2: 1408 train, 352 val]
    E --> F3[Fold 3: 1408 train, 352 val]
    E --> F4[Fold 4: 1408 train, 352 val]
    E --> F5[Fold 5: 1408 train, 352 val]

    F1 --> G[Promedio de 5 scores]
    F2 --> G
    F3 --> G
    F4 --> G
    F5 --> G

    G --> H{Â¿Mejor promedio?}
    H -->|SÃ­| I[Guardar hiperparÃ¡metros]
    H -->|No| J[Probar otros]
    J --> E

    I --> K[Entrenar con TODO Train<br/>mejores hiperparÃ¡metros]
    K --> L[EvaluaciÃ³n FINAL en Test<br/>UNA SOLA VEZ]

    style D fill:#ffcccc
    style L fill:#99ff99
```

**Â¿Por quÃ© K-Fold CV?**

| MÃ©todo | Train | Validation | Test | Evaluaciones | Robustez |
|--------|-------|------------|------|--------------|----------|
| **Hold-out (60/20/20)** | 60% | 20% | 20% | 1x | âš ï¸ Inestable |
| **K-Fold CV (80/20)** | 64% (promedio) | 16% (promedio) | 20% | 5x | âœ… Robusto |

Ventajas de K-Fold CV:
- âœ… Usa mÃ¡s datos para entrenar (64% vs 60%)
- âœ… Score mÃ¡s confiable (promedia 5 evaluaciones)
- âœ… Reduce varianza (menos dependiente de un split especÃ­fico)

#### Ejemplo PrÃ¡ctico: Random Forest

```python
from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

# Definir espacio de bÃºsqueda
param_grid = {
    'n_estimators': [50, 100, 200, 300, 500],
    'max_depth': [10, 20, 30, 40, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# RandomizedSearchCV con K-Fold CV
rf_search = RandomizedSearchCV(
    RandomForestClassifier(random_state=42),
    param_distributions=param_grid,
    n_iter=50,              # 50 combinaciones aleatorias
    cv=5,                   # 5-Fold Cross-Validation
    scoring='accuracy',
    n_jobs=-1,
    random_state=42
)

# Entrenar (K-Fold CV automÃ¡tico)
rf_search.fit(X_train, y_train)

# Mejores hiperparÃ¡metros
print(f"Best params: {rf_search.best_params_}")
print(f"Best CV score: {rf_search.best_score_:.4f}")

# Evaluar UNA VEZ en Test
print(f"Test score: {rf_search.score(X_test, y_test):.4f}")
```

#### Objetivo en este Proyecto

```mermaid
graph LR
    A[Modelo Base<br/>99.55%] --> B[OptimizaciÃ³n de<br/>HiperparÃ¡metros]
    B --> C[Feature<br/>Engineering]
    C --> D[Modelo Final<br/>99.8%+]

    B -.->|+0.1-0.2%| E[Random Forest<br/>XGBoost]
    C -.->|+0.15-0.25%| F[Nuevas Features]

    style A fill:#ffcccc
    style D fill:#99ff99
```

**Modelos a optimizar:**
- **Logistic Regression**: GridSearchCV (C, penalty, solver)
- **Decision Tree**: RandomizedSearchCV (max_depth, min_samples_split, criterion)
- **Random Forest**: RandomizedSearchCV (n_estimators, max_depth, min_samples)
- **XGBoost**: RandomizedSearchCV (learning_rate, max_depth, subsample, colsample_bytree)

---

### ğŸ§¬ Feature Engineering (IngenierÃ­a de CaracterÃ­sticas)

#### Â¿QuÃ© es Feature Engineering?

**Feature Engineering** es el proceso de crear nuevas caracterÃ­sticas (features) a partir de las existentes usando conocimiento del dominio, para mejorar el rendimiento del modelo.

```mermaid
graph LR
    A[Features Originales<br/>N, P, K, temp, humidity] --> B[Feature Engineering<br/>Conocimiento AgronÃ³mico]
    B --> C[Nuevas Features<br/>NPK, ratios, interacciones]
    C --> D[Modelo ML]
    D --> E[Mejores Predicciones]

    style B fill:#fff799
    style C fill:#99ff99
```

**Principio clave**: *"Los datos correctos vencen a los algoritmos sofisticados"*

#### Â¿Por quÃ© es Importante?

```mermaid
graph TD
    A[Features Originales<br/>7 variables] --> B[Accuracy: 95-99%]

    C[Features + Engineering<br/>12 variables] --> D[Accuracy: 99%+]

    B --> E[Modelo aprende<br/>relaciones bÃ¡sicas]
    D --> F[Modelo aprende<br/>relaciones complejas<br/>pre-calculadas]

    style A fill:#ffcccc
    style C fill:#99ff99
    style D fill:#99ff99
```

**Beneficios:**
- âœ… **Mejora rendimiento**: +1% a +5% de accuracy
- âœ… **Captura relaciones ocultas**: Sinergia entre variables
- âœ… **Mejora interpretabilidad**: Features con significado agronÃ³mico
- âœ… **Reduce complejidad**: El modelo aprende mÃ¡s fÃ¡cil

#### Tipos de Features en este Proyecto

```mermaid
graph TD
    A[Features Originales<br/>7 variables] --> B[Feature Engineering]

    B --> C[1. Interacciones<br/>MultiplicaciÃ³n]
    B --> D[2. Ratios<br/>DivisiÃ³n]
    B --> E[3. Agregaciones<br/>EstadÃ­sticas]

    C --> F[N*P*K<br/>temp*humidity]
    D --> G[N/P, K/P, N/K]
    E --> H[avg_nutrients<br/>avg_climate]

    F --> I[Dataset Enriquecido<br/>~13-15 features]
    G --> I
    H --> I

    style B fill:#fff799
    style I fill:#99ff99
```

##### 1. Features de InteracciÃ³n (MultiplicaciÃ³n)

Capturan **sinergia** entre variables:

```python
# NPK: Ãndice de fertilidad total (sinergia de nutrientes)
df['NPK_total'] = df['N'] * df['P'] * df['K']

# Ãndice de estrÃ©s climÃ¡tico (interacciÃ³n temp-humedad)
df['temp_humidity_index'] = df['temperature'] * df['humidity']

# InteracciÃ³n N-P (correlaciÃ³n alta detectada en EDA)
df['NP_interaction'] = df['N'] * df['P']
```

**JustificaciÃ³n agronÃ³mica:**

```mermaid
graph LR
    A[N solo] -.->|Efecto limitado| D[Crecimiento]
    B[P solo] -.->|Efecto limitado| D
    C[K solo] -.->|Efecto limitado| D

    E[N Ã— P Ã— K] ==>|SINERGIA| F[Crecimiento Ã“ptimo]

    style E fill:#99ff99
    style F fill:#99ff99
```

- Los nutrientes trabajan en **sinergia**: la falta de uno limita el efecto de los otros
- Temperatura y humedad combinadas determinan el estrÃ©s de la planta

##### 2. Features de Ratios (Divisiones)

Capturan **balances** entre variables:

```python
# Ratios de nutrientes
df['N_P_ratio'] = df['N'] / (df['P'] + 1e-5)  # +epsilon evita divisiÃ³n por 0
df['K_P_ratio'] = df['K'] / (df['P'] + 1e-5)
df['N_K_ratio'] = df['N'] / (df['K'] + 1e-5)
```

**JustificaciÃ³n agronÃ³mica:**

```mermaid
graph TD
    A[MaÃ­z<br/>Prefiere N/P = 2:1] --> C{N/P ratio}
    B[Arroz<br/>Prefiere N/P = 4:1] --> C

    C -->|2.0| D[âœ“ Predice: MaÃ­z]
    C -->|4.0| E[âœ“ Predice: Arroz]

    style D fill:#99ff99
    style E fill:#99ff99
```

- Los cultivos necesitan **proporciones especÃ­ficas**, no solo cantidades absolutas
- Un ratio N/P de 2:1 es ideal para maÃ­z, pero 4:1 para arroz

##### 3. Features Agregadas

EstadÃ­sticas resumen:

```python
# Promedio de nutrientes
df['nutrient_avg'] = (df['N'] + df['P'] + df['K']) / 3

# DesviaciÃ³n estÃ¡ndar (balance de nutrientes)
df['nutrient_std'] = df[['N', 'P', 'K']].std(axis=1)
```

#### EvaluaciÃ³n con SHAP (Feature Importance)

```mermaid
graph TD
    A[Modelo Entrenado] --> B[SHAP Analysis]
    C[Features: originales + engineered] --> B

    B --> D[SHAP Values]
    D --> E[Importancia Global]
    D --> F[ContribuciÃ³n por PredicciÃ³n]

    E --> G{Â¿Feature importante?}
    G -->|SHAP alto| H[âœ“ Conservar]
    G -->|SHAP bajo| I[âœ— Eliminar]

    style B fill:#fff799
    style H fill:#99ff99
    style I fill:#ffcccc
```

**SHAP (SHapley Additive exPlanations)** permite:
- âœ… Identificar features mÃ¡s importantes
- âœ… Validar que las nuevas features aportan valor
- âœ… Eliminar features redundantes

```python
import shap

# Calcular importancia
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Visualizar
shap.summary_plot(shap_values, X_test)
```

#### Pipeline Completo

```mermaid
graph TD
    A[Datos Originales<br/>7 features] --> B[Crear Features<br/>interacciones, ratios]

    B --> C[Dataset Expandido<br/>~13-15 features]

    C --> D[Entrenar con<br/>hiperparÃ¡metros Ã³ptimos]
    D --> E[AnÃ¡lisis SHAP]

    E --> F{Seleccionar<br/>Top Features}
    F --> G[Features Finales<br/>10-12 mÃ¡s importantes]

    G --> H[Modelo Final]
    H --> I[Comparar vs Baseline]

    style A fill:#ffcccc
    style C fill:#fff799
    style G fill:#ccffcc
    style I fill:#99ff99
```

#### Objetivo en este Proyecto

**Features a crear:**
1. **Sinergia de nutrientes**: NÃ—PÃ—K, NÃ—P
2. **EstrÃ©s ambiental**: temperatureÃ—humidity
3. **Balance nutricional**: N/P, K/P, N/K
4. **Agregaciones**: promedios, desviaciones

**ComparaciÃ³n esperada:**

```mermaid
graph LR
    A[Sin Feature Engineering<br/>7 features<br/>99.55%] --> C[AnÃ¡lisis]

    B[Con Feature Engineering<br/>12 features<br/>99.8%+] --> C

    C --> D[Mejor modelo<br/>+ interpretable]

    style B fill:#99ff99
    style D fill:#99ff99
```

---

## ğŸ“Š CaracterÃ­sticas del Dataset

| CaracterÃ­stica | Tipo | DescripciÃ³n | Unidad |
|---------------|------|-------------|--------|
| N | NumÃ©rico | Contenido de NitrÃ³geno | kg/ha |
| P | NumÃ©rico | Contenido de FÃ³sforo | kg/ha |
| K | NumÃ©rico | Contenido de Potasio | kg/ha |
| temperature | NumÃ©rico | Temperatura | Â°C |
| humidity | NumÃ©rico | Humedad | % |
| ph | NumÃ©rico | Valor de pH | - |
| rainfall | NumÃ©rico | PrecipitaciÃ³n | mm |
| label | CategÃ³rico | Tipo de cultivo | 22 clases |

### ğŸŒ± Cultivos Incluidos (22 clases)

Arroz, MaÃ­z, Garbanzo, Frijol, Guisante, Frijol Polilla, Frijol Mungo, Granada, PlÃ¡tano, Mango, Uvas, AlgodÃ³n, Yute, Gramo Negro, SandÃ­a, MelÃ³n, Manzana, Naranja, Papaya, Coco, Lenteja, CafÃ©

## ğŸ“ˆ Criterios de Ã‰xito

### TÃ©cnicos
- âœ… Accuracy â‰¥ 95%
- âœ… Precision y Recall â‰¥ 90% por clase
- âœ… F1-Score â‰¥ 90%
- âœ… Modelo interpretable

### De Negocio
- âœ… Recomendaciones accionables
- âœ… Tiempo de predicciÃ³n < 1 segundo
- âœ… Sistema escalable
- âœ… Confianza del usuario (explicabilidad)

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Lenguaje**: Python 3.12+
- **AnÃ¡lisis de Datos**: pandas, numpy
- **VisualizaciÃ³n**: matplotlib, seaborn, plotly
- **Machine Learning**: scikit-learn, xgboost, lightgbm
- **Interpretabilidad**: SHAP
- **Notebooks**: Jupyter Lab
- **Control de versiones**: Git

## ğŸ“ GuÃ­a de ContribuciÃ³n

1. Fork el proyecto
2. Crear una rama (`git checkout -b feature/nueva-caracteristica`)
3. Commit cambios (`git commit -m 'Agregar nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/nueva-caracteristica`)
5. Crear Pull Request

## ğŸ‘¥ Autor(es)

- Daniel Alejandro Garcia Zuluaica
- Elizabeth Toro Chalarca
- Edward Alejandro Rayo CortÃ©s

**Universidad**: EAFIT
**Curso**: Aprendizaje de MÃ¡quina Aplicado

## ğŸ“š Referencias

1. IBM SPSS Modeler. (2012). *CRISP-DM Guide*. IBM Corporation.
2. Crop Recommendation Dataset. Kaggle. https://www.kaggle.com/datasets/atharvaingle/crop-recommendation-dataset
3. Scikit-learn Documentation. https://scikit-learn.org/
4. Lundberg, S. M., & Lee, S. I. (2017). *A unified approach to interpreting model predictions*. NeurIPS.

## ğŸ“„ Licencia

Este proyecto es un trabajo acadÃ©mico para el curso de Aprendizaje de MÃ¡quina Aplicado en EAFIT.

## ğŸ¤ Agradecimientos

- Profesor: Marco TerÃ¡n
- Universidad EAFIT
- Comunidad de Kaggle por el dataset

---

**Ãšltima actualizaciÃ³n**: Septiembre 2025

**Estado del Proyecto**: ğŸš§ En desarrollo