# GuÃ­a del Sistema de Split Centralizado de Datos

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa un **sistema de split Train/Test centralizado** que garantiza que todos los notebooks usen exactamente los mismos datos de entrenamiento y prueba, siguiendo las mejores prÃ¡cticas de Machine Learning.

## ğŸ¯ Objetivo

**Prevenir data leakage** y garantizar evaluaciones justas al:

1. âœ… Realizar el split Train/Test **UNA SOLA VEZ** al inicio
2. âœ… Usar **SOLO datos de entrenamiento** para:
   - Feature engineering
   - Entrenamiento de modelos
   - OptimizaciÃ³n de hiperparÃ¡metros
   - ValidaciÃ³n cruzada
3. âœ… Reservar **datos de prueba** Ãºnicamente para evaluaciÃ³n final

## ğŸ“ Estructura

```
proyecto_final/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py          # Carga el dataset desde Kaggle
â”‚   â””â”€â”€ data_split.py           # â­ MÃ³dulo de split centralizado
â”œâ”€â”€ models/
â”‚   â””â”€â”€ train_test_split_cache.pkl  # Cache del split (automÃ¡tico)
â””â”€â”€ notebooks/
    â”œâ”€â”€ 2_crops_modeling.ipynb
    â”œâ”€â”€ 2.5_hyperparameter_optimization.ipynb
    â””â”€â”€ 3_crops_feature_engineering.ipynb
```

## ğŸš€ Uso en Notebooks

### Importar el mÃ³dulo

```python
import sys
sys.path.append('../src')

from data_split import get_train_test_split

# Obtener split (automÃ¡ticamente usa el mismo split en todos los notebooks)
data = get_train_test_split()
```

### Extraer datos

```python
# Features de entrenamiento y prueba
X_train = data['X_train']
X_test = data['X_test']

# Target de entrenamiento y prueba (codificado)
y_train = data['y_train']
y_test = data['y_test']

# Target con etiquetas originales (opcional)
y_train_labels = data['y_train_labels']
y_test_labels = data['y_test_labels']

# Label encoder (para decodificar predicciones)
label_encoder = data['label_encoder']

# Metadata
feature_names = data['feature_names']  # ['N', 'P', 'K', ...]
class_names = data['class_names']      # ['apple', 'banana', ...]
split_info = data['split_info']        # Info del split
```

### Estructura del diccionario `data`

```python
{
    'X_train': DataFrame,           # Features de entrenamiento (1760 Ã— 7)
    'X_test': DataFrame,            # Features de prueba (440 Ã— 7)
    'y_train': ndarray,             # Target entrenamiento codificado (1760,)
    'y_test': ndarray,              # Target prueba codificado (440,)
    'y_train_labels': Series,       # Target entrenamiento original (1760,)
    'y_test_labels': Series,        # Target prueba original (440,)
    'label_encoder': LabelEncoder,  # Encoder entrenado
    'feature_names': list,          # Nombres de features
    'class_names': list,            # Nombres de clases
    'split_info': dict              # Metadata del split
}
```

## ğŸ“Š ConfiguraciÃ³n del Split

Por defecto, el split usa:

- **Test size**: 20% (440 muestras)
- **Train size**: 80% (1760 muestras)
- **Random state**: 42 (reproducibilidad)
- **EstratificaciÃ³n**: SÃ­ (mantiene proporciÃ³n de clases)

### Personalizar el split

```python
# Crear un nuevo split con diferentes parÃ¡metros
data = get_train_test_split(
    use_cache=False,      # No usar cache, crear nuevo split
    random_state=42,      # Semilla
    test_size=0.25        # 25% para test
)
```

### Regenerar el split

```python
from data_split import clear_cache

# Eliminar cache actual
clear_cache()

# El prÃ³ximo get_train_test_split() crearÃ¡ un nuevo split
data = get_train_test_split()
```

## ğŸ”„ Flujo de Trabajo

### Notebook 2: Modelado Base

```python
# 1. Obtener split
data = get_train_test_split()
X_train, X_test = data['X_train'], data['X_test']
y_train, y_test = data['y_train'], data['y_test']

# 2. Entrenar SOLO con datos de train
model.fit(X_train, y_train)

# 3. Evaluar SOLO con datos de test (al final)
accuracy = model.score(X_test, y_test)
```

### Notebook 2.5: OptimizaciÃ³n de HiperparÃ¡metros

```python
# 1. Obtener el MISMO split
data = get_train_test_split()
X_train, y_train = data['X_train'], data['y_train']

# 2. Optimizar SOLO con datos de train (usando CV interno)
grid_search = GridSearchCV(model, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# 3. Evaluar SOLO con datos de test (al final)
best_model = grid_search.best_estimator_
accuracy = best_model.score(X_test, y_test)
```

### Notebook 3: Feature Engineering

```python
# 1. Obtener el MISMO split
data = get_train_test_split()
X_train_original = data['X_train']

# 2. Feature engineering SOLO en datos de train
X_train_engineered = create_features(X_train_original)

# 3. Aplicar MISMAS transformaciones a test
X_test_original = data['X_test']
X_test_engineered = create_features(X_test_original)

# 4. Entrenar y evaluar
model.fit(X_train_engineered, y_train)
accuracy = model.score(X_test_engineered, y_test)
```

## âœ… Ventajas del Sistema

1. **Consistencia**: Todos los notebooks usan exactamente el mismo split
2. **PrevenciÃ³n de data leakage**: Los datos de test nunca se usan para entrenamiento
3. **Reproducibilidad**: Random state fijo + cache garantiza resultados consistentes
4. **Simplicidad**: Una sola lÃ­nea de cÃ³digo para obtener todos los datos
5. **Cache automÃ¡tico**: El split se guarda y reutiliza automÃ¡ticamente
6. **Trazabilidad**: Metadata completa del split disponible en `split_info`

## ğŸ” Verificar Consistencia

Para verificar que todos los notebooks usan el mismo split:

```python
from data_split import print_split_summary

data = get_train_test_split()
print_split_summary(data)
```

Output esperado:

```
================================================================================
                          RESUMEN DEL SPLIT TRAIN/TEST
================================================================================

ğŸ“Š TamaÃ±o del Dataset:
   - Total: 2200 muestras
   - Train: 1760 muestras (80.0%)
   - Test: 440 muestras (20.0%)

ğŸ”¢ CaracterÃ­sticas:
   - Features: 7
   - Clases: 22

âš™ï¸  ConfiguraciÃ³n:
   - Random state: 42
   - Estratificado: SÃ­
```

## ğŸ› Troubleshooting

### Error: "ModuleNotFoundError: No module named 'data_split'"

**SoluciÃ³n**: AsegÃºrate de agregar el path al sys.path:

```python
import sys
sys.path.append('../src')  # Ajustar segÃºn ubicaciÃ³n del notebook
```

### Error: Cache corrupto

**SoluciÃ³n**: Regenerar el cache:

```python
from data_split import clear_cache
clear_cache()
data = get_train_test_split()
```

### Los notebooks muestran diferentes resultados

**VerificaciÃ³n**: Confirmar que todos usan el mismo split:

```python
# En cada notebook:
print(f"Train samples: {len(X_train)}")  # Debe ser 1760
print(f"Test samples: {len(X_test)}")     # Debe ser 440
print(f"First train index: {X_train.index[0]}")  # Debe ser igual en todos
```

## ğŸ“ Notas Importantes

1. **El split se hace UNA VEZ**: El primer notebook que se ejecute crearÃ¡ el cache
2. **Cache compartido**: El archivo `train_test_split_cache.pkl` es usado por todos los notebooks
3. **No modificar X_train/X_test manualmente**: Usar copias si necesitas transformaciones
4. **Feature engineering**: Aplicar transformaciones a train primero, luego a test con los mismos parÃ¡metros

## ğŸ“š Referencias

- **Archivo fuente**: `src/data_split.py`
- **DocumentaciÃ³n sklearn**: [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- **Data leakage**: [Kaggle Guide](https://www.kaggle.com/code/alexisbcook/data-leakage)

---

**Creado para**: Proyecto Final - Machine Learning Aplicado
**Universidad**: EAFIT
**Fecha**: Octubre 2025

